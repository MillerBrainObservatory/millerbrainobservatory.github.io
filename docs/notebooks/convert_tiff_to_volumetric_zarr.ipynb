{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Multi-Camera TIFF Stacks to Volumetric OME-Zarr\n",
    "\n",
    "This notebook converts IsoView TIFF stacks (converted from KLB) into volumetric OME-Zarr files.\n",
    "\n",
    "## Structure\n",
    "- Each timepoint directory (TM000000, TM000001, ...) contains:\n",
    "  - 4 cameras × TIFF stacks (79 z-planes each)\n",
    "  - XML metadata files (one per camera)\n",
    "  - MAT files (minIntensity, configuration)\n",
    "\n",
    "## Output\n",
    "- One OME-Zarr volume per camera per timepoint\n",
    "- Conforms to OME-NGFF v0.5 specification\n",
    "- Metadata extracted from XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mbo_utilities as mbo\n",
    "from mbo_utilities._writers import _write_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: \\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\tiff\n",
      "Output: \\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\zarr\n",
      "Source exists: True\n",
      "Compression level: 1\n",
      "Sharding: True\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "SOURCE_ROOT = Path(r\"\\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\tiff\")\n",
    "OUTPUT_ROOT = Path(r\"\\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\zarr\")\n",
    "\n",
    "# Processing options\n",
    "COMPRESSION_LEVEL = 1  # GZip compression level (1-9, lower = faster)\n",
    "USE_SHARDING = True     # Use Zarr v3 sharding for better performance\n",
    "OVERWRITE = True        # Overwrite existing zarr files\n",
    "\n",
    "# Pattern matching\n",
    "CAMERA_PATTERN = \"SPM00_TM*_CM*.tif\"  # Match camera TIFF files\n",
    "XML_PATTERN = \"SPM00_TM*_CM*.xml\"     # Match XML metadata files\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Source: {SOURCE_ROOT}\")\n",
    "print(f\"Output: {OUTPUT_ROOT}\")\n",
    "print(f\"Source exists: {SOURCE_ROOT.exists()}\")\n",
    "print(f\"Compression level: {COMPRESSION_LEVEL}\")\n",
    "print(f\"Sharding: {USE_SHARDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def parse_isoview_xml(xml_path: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse IsoView XML metadata file from push_config format.\n",
    "\n",
    "    Returns dict with keys:\n",
    "    - z_step: z-step size in micrometers\n",
    "    - dimensions: image dimensions\n",
    "    - exposure_time: exposure time in ms\n",
    "    - wavelength: illumination wavelength\n",
    "    - camera_type: camera model\n",
    "    - timestamp: acquisition timestamp\n",
    "    \"\"\"\n",
    "    if not xml_path.exists():\n",
    "        print(f\"Warning: XML file not found: {xml_path}\")\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        metadata = {}\n",
    "\n",
    "        # Parse all <info> elements\n",
    "        for info in root.findall('.//info'):\n",
    "            key = list(info.attrib.keys())[0] if info.attrib else None\n",
    "            value = info.get(key) if key else None\n",
    "\n",
    "            if key and value:\n",
    "                # Store specific fields we care about\n",
    "                if key == 'z_step':\n",
    "                    metadata['z_step'] = float(value)\n",
    "                elif key == 'dimensions':\n",
    "                    metadata['dimensions'] = value\n",
    "                elif key == 'exposure_time':\n",
    "                    metadata['exposure_time'] = float(value)\n",
    "                elif key == 'wavelength':\n",
    "                    metadata['wavelength'] = int(value)\n",
    "                elif key == 'camera_type':\n",
    "                    metadata['camera_type'] = value\n",
    "                elif key == 'timestamp':\n",
    "                    metadata['timestamp'] = value\n",
    "                elif key == 'time_point':\n",
    "                    metadata['time_point'] = int(value)\n",
    "                elif key == 'planes':\n",
    "                    metadata['planes'] = value\n",
    "                elif key == 'detection_objective':\n",
    "                    metadata['detection_objective'] = value\n",
    "\n",
    "        # Format for mbo_utilities\n",
    "        # Default pixel sizes (can be refined if known)\n",
    "        metadata['pixel_resolution'] = (0.65, 0.65)  # Approximate for 20x objective\n",
    "\n",
    "        # Use z_step if available\n",
    "        if 'z_step' in metadata:\n",
    "            metadata['dz'] = metadata['z_step']\n",
    "        else:\n",
    "            metadata['dz'] = 1.0  # Default\n",
    "\n",
    "        # Frame rate (IsoView typically ~1-10 fps depending on config)\n",
    "        metadata['frame_rate'] = 1.0  # Default, update if known\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML {xml_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_camera_files(timepoint_dir: Path) -> List[Tuple[Path, Path]]:\n",
    "    \"\"\"\n",
    "    Get all camera TIFF files and their corresponding XML files for a timepoint.\n",
    "\n",
    "    IsoView file naming:\n",
    "    - TIFF: SPM00_TM000000_CM00_CHN01.tif (camera 00, channel 01)\n",
    "    - XML:  SPM00_TM000000_CHN01.xml (channel 01 - shared across cameras)\n",
    "\n",
    "    Returns list of (tiff_path, xml_path) tuples.\n",
    "    \"\"\"\n",
    "    tiff_files = sorted(timepoint_dir.glob(CAMERA_PATTERN))\n",
    "\n",
    "    camera_pairs = []\n",
    "    for tiff_path in tiff_files:\n",
    "        # Extract channel from filename: SPM00_TM000000_CM00_CHN01.tif -> CHN01\n",
    "        # Pattern: SPM00_TM{timepoint}_CM{camera}_CHN{channel}.tif\n",
    "        parts = tiff_path.stem.split('_')\n",
    "\n",
    "        # Find the CHN part\n",
    "        channel = None\n",
    "        for part in parts:\n",
    "            if part.startswith('CHN'):\n",
    "                channel = part\n",
    "                break\n",
    "\n",
    "        if channel:\n",
    "            # Construct XML filename: SPM00_TM{timepoint}_CHN{channel}.xml\n",
    "            timepoint = parts[1]  # TM000000\n",
    "            xml_name = f\"SPM00_{timepoint}_{channel}.xml\"\n",
    "            xml_path = timepoint_dir / xml_name\n",
    "\n",
    "            camera_pairs.append((tiff_path, xml_path))\n",
    "        else:\n",
    "            print(f\"Warning: Could not extract channel from {tiff_path.name}\")\n",
    "            # Fallback: try with .xml extension (will likely not exist)\n",
    "            xml_path = tiff_path.with_suffix('.xml')\n",
    "            camera_pairs.append((tiff_path, xml_path))\n",
    "\n",
    "    return camera_pairs\n",
    "\n",
    "\n",
    "def get_timepoint_dirs(source_root: Path) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Get all timepoint directories (TM000000, TM000001, ...).\n",
    "    \"\"\"\n",
    "    dirs = sorted([d for d in source_root.iterdir() if d.is_dir() and d.name.startswith('TM')])\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def get_output_path(camera_tiff_path: Path, output_root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Generate output zarr path from input TIFF path.\n",
    "\n",
    "    Example:\n",
    "    Input:  .../TM000001/SPM00_TM000001_CM00_CHN01.tif\n",
    "    Output: .../TM000001/SPM00_TM000001_CM00_CHN01.zarr\n",
    "    \"\"\"\n",
    "    timepoint_name = camera_tiff_path.parent.name\n",
    "    camera_name = camera_tiff_path.stem  # Remove .tif extension\n",
    "\n",
    "    output_dir = output_root / timepoint_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return output_dir / f\"{camera_name}.zarr\"\n",
    "\n",
    "\n",
    "print(\"Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 201 timepoint directories\n",
      "Range: TM000000 to TM000200\n",
      "\n",
      "First timepoint has 4 camera files\n"
     ]
    }
   ],
   "source": [
    "# Get all timepoint directories\n",
    "timepoint_dirs = get_timepoint_dirs(SOURCE_ROOT)\n",
    "\n",
    "print(f\"Found {len(timepoint_dirs)} timepoint directories\")\n",
    "print(f\"Range: {timepoint_dirs[0].name} to {timepoint_dirs[-1].name}\")\n",
    "\n",
    "# Check first timepoint structure\n",
    "if timepoint_dirs:\n",
    "    first_tp = timepoint_dirs[0]\n",
    "    camera_files = get_camera_files(first_tp)\n",
    "    print(f\"\\nFirst timepoint has {len(camera_files)} camera files\")\n",
    "\n",
    "    # Check for missing XML files\n",
    "    missing_xml = [xml for _, xml in camera_files if not xml.exists()]\n",
    "    if missing_xml:\n",
    "        print(f\"WARNING: {len(missing_xml)} XML files not found\")\n",
    "        for xml in missing_xml[:3]:\n",
    "            print(f\"  Missing: {xml.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metadata Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing metadata extraction:\n",
      "  TIFF: SPM00_TM000000_CM00_CHN01.tif\n",
      "  XML:  SPM00_TM000000_CHN01.xml\n",
      "\n",
      "Extracted metadata:\n",
      "  z_step: 5.13\n",
      "  wavelength: 488\n",
      "  exposure_time: 4.8\n",
      "  camera_type: C11440-22C,C11440-22C\n",
      "  dimensions: 2048x752x79,2048x752x79\n"
     ]
    }
   ],
   "source": [
    "# Test metadata parsing on first file\n",
    "if timepoint_dirs:\n",
    "    first_tp = timepoint_dirs[0]\n",
    "    camera_files = get_camera_files(first_tp)\n",
    "\n",
    "    if camera_files:\n",
    "        test_tiff, test_xml = camera_files[0]\n",
    "        print(f\"Testing metadata extraction:\")\n",
    "        print(f\"  TIFF: {test_tiff.name}\")\n",
    "        print(f\"  XML:  {test_xml.name}\")\n",
    "\n",
    "        # Check if XML exists and parse\n",
    "        if test_xml.exists():\n",
    "            metadata = parse_isoview_xml(test_xml)\n",
    "\n",
    "            if metadata:\n",
    "                print(f\"\\nExtracted metadata:\")\n",
    "                # Show only the most important fields\n",
    "                for key in ['z_step', 'wavelength', 'exposure_time', 'camera_type', 'dimensions']:\n",
    "                    if key in metadata:\n",
    "                        print(f\"  {key}: {metadata[key]}\")\n",
    "            else:\n",
    "                print(\"\\nWARNING: Failed to parse XML metadata\")\n",
    "        else:\n",
    "            print(f\"\\nERROR: XML file not found\")\n",
    "            print(f\"Expected: {test_xml.name}\")\n",
    "\n",
    "            # List available XML files\n",
    "            xml_files = list(test_xml.parent.glob(\"*.xml\"))\n",
    "            if xml_files:\n",
    "                print(f\"\\nAvailable XML files in {test_xml.parent.name}:\")\n",
    "                for xf in xml_files:\n",
    "                    print(f\"  {xf.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Single Conversion\n",
    "\n",
    "Convert one camera file to verify the process works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test conversion: SPM00_TM000000_CM00_CHN01.tif\n",
      "  Input shape: (79, 752, 2048), dtype: uint16\n",
      "  Conversion: 2.2s @ 46.6 MB/s\n",
      "  Size: 232.1 MB → 101.9 MB (2.28x compression)\n",
      "  Verified: (79, 1, 752, 2048)\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "\n",
    "if timepoint_dirs:\n",
    "    # Test on first camera of first timepoint\n",
    "    test_tp = timepoint_dirs[0]\n",
    "    camera_files = get_camera_files(test_tp)\n",
    "\n",
    "    if camera_files:\n",
    "        test_tiff, test_xml = camera_files[0]\n",
    "        test_output = get_output_path(test_tiff, OUTPUT_ROOT)\n",
    "\n",
    "        print(f\"Test conversion: {test_tiff.name}\")\n",
    "\n",
    "        # Read TIFF stack using tifffile directly\n",
    "        stack = tifffile.imread(test_tiff)\n",
    "        print(f\"  Input shape: {stack.shape}, dtype: {stack.dtype}\")\n",
    "\n",
    "        # Parse metadata\n",
    "        metadata = parse_isoview_xml(test_xml)\n",
    "\n",
    "        # Stack should be (Z, Y, X) for a single volume\n",
    "        if stack.ndim == 2:\n",
    "            data = stack[np.newaxis, ...]\n",
    "        elif stack.ndim == 3:\n",
    "            data = stack\n",
    "        else:\n",
    "            print(f\"  WARNING: Unexpected dimensions: {stack.ndim}\")\n",
    "            data = stack\n",
    "\n",
    "        # Ensure all required metadata fields\n",
    "        if 'num_frames' not in metadata:\n",
    "            metadata['num_frames'] = data.shape[0]\n",
    "        if 'dz' not in metadata:\n",
    "            metadata['dz'] = 5.13\n",
    "        if 'pixel_resolution' not in metadata:\n",
    "            metadata['pixel_resolution'] = (0.65, 0.65)\n",
    "        if 'frame_rate' not in metadata:\n",
    "            metadata['frame_rate'] = 1.0\n",
    "\n",
    "        # Clear any cached zarr writers\n",
    "        if hasattr(_write_zarr, '_arrays'):\n",
    "            _write_zarr._arrays.clear()\n",
    "            _write_zarr._offsets.clear()\n",
    "            _write_zarr._groups.clear()\n",
    "\n",
    "        # Convert to OME-Zarr\n",
    "        start_time = time.time()\n",
    "\n",
    "        _write_zarr(\n",
    "            test_output,\n",
    "            data,\n",
    "            metadata=metadata,\n",
    "            ome=True,\n",
    "            sharded=USE_SHARDING,\n",
    "            level=COMPRESSION_LEVEL,\n",
    "            overwrite=OVERWRITE\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # Calculate statistics\n",
    "        input_size_mb = test_tiff.stat().st_size / (1024**2)\n",
    "        output_size_mb = sum(f.stat().st_size for f in test_output.rglob('*') if f.is_file()) / (1024**2)\n",
    "        compression_ratio = input_size_mb / output_size_mb if output_size_mb > 0 else 0\n",
    "        throughput_mb_s = output_size_mb / elapsed if elapsed > 0 else 0\n",
    "\n",
    "        print(f\"  Conversion: {elapsed:.1f}s @ {throughput_mb_s:.1f} MB/s\")\n",
    "        print(f\"  Size: {input_size_mb:.1f} MB → {output_size_mb:.1f} MB ({compression_ratio:.2f}x compression)\")\n",
    "\n",
    "        # Verify readback\n",
    "        try:\n",
    "            verified = mbo.imread(test_output)\n",
    "            print(f\"  Verified: {verified.shape}\")\n",
    "        except Exception as e:\n",
    "            # Try with zarr directly\n",
    "            try:\n",
    "                import zarr\n",
    "                z = zarr.open(test_output, mode='r')\n",
    "                print(f\"  Verified: {z.shape}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"  WARNING: Verification failed: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Conversion\n",
    "\n",
    "Convert all camera files across all timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 201 timepoints...\n",
      "================================================================================\n",
      "[10/201] TM000009: 4 ok (13.0s)\n",
      "[20/201] TM000019: 4 ok (13.9s)\n",
      "[30/201] TM000029: 4 ok (15.1s)\n",
      "[40/201] TM000039: 4 ok (15.2s)\n",
      "[50/201] TM000049: 4 ok (15.8s)\n",
      "[60/201] TM000059: 4 ok (14.6s)\n",
      "[70/201] TM000069: 4 ok (13.5s)\n",
      "[80/201] TM000079: 4 ok (14.1s)\n",
      "[90/201] TM000089: 4 ok (13.3s)\n",
      "[100/201] TM000099: 4 ok (13.5s)\n",
      "[110/201] TM000109: 4 ok (14.9s)\n",
      "[120/201] TM000119: 4 ok (15.4s)\n",
      "[130/201] TM000129: 4 ok (15.2s)\n",
      "[140/201] TM000139: 4 ok (12.8s)\n",
      "[150/201] TM000149: 4 ok (12.3s)\n",
      "[160/201] TM000159: 4 ok (14.5s)\n",
      "[170/201] TM000169: 4 ok (14.7s)\n",
      "[180/201] TM000179: 4 ok (14.1s)\n",
      "[190/201] TM000189: 4 ok (15.2s)\n",
      "[200/201] TM000199: 4 ok (14.7s)\n",
      "[201/201] TM000200: 4 ok (14.3s)\n",
      "\n",
      "================================================================================\n",
      "Completed in 2824.0s (47.1 min)\n",
      "  Successful: 804\n"
     ]
    }
   ],
   "source": [
    "# Statistics tracking\n",
    "conversion_stats = []\n",
    "failed_conversions = []\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "print(f\"Converting {len(timepoint_dirs)} timepoints...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for tp_idx, tp_dir in enumerate(timepoint_dirs, 1):\n",
    "    # Get all camera files for this timepoint\n",
    "    camera_files = get_camera_files(tp_dir)\n",
    "\n",
    "    if not camera_files:\n",
    "        print(f\"[{tp_idx}/{len(timepoint_dirs)}] {tp_dir.name}: No camera files found\")\n",
    "        continue\n",
    "\n",
    "    tp_start_time = time.time()\n",
    "    tp_successes = 0\n",
    "    tp_failures = 0\n",
    "\n",
    "    for cam_idx, (tiff_path, xml_path) in enumerate(camera_files, 1):\n",
    "        output_path = get_output_path(tiff_path, OUTPUT_ROOT)\n",
    "\n",
    "        # Skip if already exists and not overwriting\n",
    "        if output_path.exists() and not OVERWRITE:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            file_start_time = time.time()\n",
    "\n",
    "            # Read TIFF using tifffile directly\n",
    "            stack = tifffile.imread(tiff_path)\n",
    "\n",
    "            # Ensure correct shape (Z, Y, X)\n",
    "            if stack.ndim == 2:\n",
    "                data = stack[np.newaxis, ...]\n",
    "            elif stack.ndim == 3:\n",
    "                data = stack\n",
    "            else:\n",
    "                data = stack\n",
    "\n",
    "            # Parse metadata\n",
    "            metadata = parse_isoview_xml(xml_path)\n",
    "\n",
    "            # Ensure all required metadata fields\n",
    "            if 'num_frames' not in metadata:\n",
    "                metadata['num_frames'] = data.shape[0]\n",
    "            if 'dz' not in metadata:\n",
    "                metadata['dz'] = 5.13\n",
    "            if 'pixel_resolution' not in metadata:\n",
    "                metadata['pixel_resolution'] = (0.65, 0.65)\n",
    "            if 'frame_rate' not in metadata:\n",
    "                metadata['frame_rate'] = 1.0\n",
    "\n",
    "            # Clear zarr cache\n",
    "            if hasattr(_write_zarr, '_arrays'):\n",
    "                _write_zarr._arrays.clear()\n",
    "                _write_zarr._offsets.clear()\n",
    "                _write_zarr._groups.clear()\n",
    "\n",
    "            # Write OME-Zarr\n",
    "            _write_zarr(\n",
    "                output_path,\n",
    "                data,\n",
    "                metadata=metadata,\n",
    "                ome=True,\n",
    "                sharded=USE_SHARDING,\n",
    "                level=COMPRESSION_LEVEL,\n",
    "                overwrite=OVERWRITE\n",
    "            )\n",
    "\n",
    "            file_elapsed = time.time() - file_start_time\n",
    "\n",
    "            # Calculate sizes\n",
    "            input_size_mb = tiff_path.stat().st_size / (1024**2)\n",
    "            output_size_mb = sum(f.stat().st_size for f in output_path.rglob('*') if f.is_file()) / (1024**2)\n",
    "            compression_ratio = input_size_mb / output_size_mb if output_size_mb > 0 else 0\n",
    "            throughput = output_size_mb / file_elapsed if file_elapsed > 0 else 0\n",
    "\n",
    "            # Record stats\n",
    "            conversion_stats.append({\n",
    "                'timepoint': tp_dir.name,\n",
    "                'camera_file': tiff_path.name,\n",
    "                'input_size_mb': input_size_mb,\n",
    "                'output_size_mb': output_size_mb,\n",
    "                'compression_ratio': compression_ratio,\n",
    "                'time_sec': file_elapsed,\n",
    "                'throughput_mb_per_sec': throughput,\n",
    "                'num_z_planes': data.shape[0],\n",
    "                'success': True\n",
    "            })\n",
    "\n",
    "            tp_successes += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{tp_idx}/{len(timepoint_dirs)}] {tp_dir.name}/{tiff_path.name}: ERROR - {e}\")\n",
    "            failed_conversions.append({\n",
    "                'timepoint': tp_dir.name,\n",
    "                'camera_file': tiff_path.name,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            tp_failures += 1\n",
    "            continue\n",
    "\n",
    "    tp_elapsed = time.time() - tp_start_time\n",
    "\n",
    "    # Only print if there were issues or every 10 timepoints\n",
    "    if tp_failures > 0 or tp_idx % 10 == 0 or tp_idx == len(timepoint_dirs):\n",
    "        status = f\"{tp_successes} ok\" + (f\", {tp_failures} failed\" if tp_failures > 0 else \"\")\n",
    "        print(f\"[{tp_idx}/{len(timepoint_dirs)}] {tp_dir.name}: {status} ({tp_elapsed:.1f}s)\")\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Completed in {total_elapsed:.1f}s ({total_elapsed/60:.1f} min)\")\n",
    "print(f\"  Successful: {len(conversion_stats)}\")\n",
    "if failed_conversions:\n",
    "    print(f\"  Failed: {len(failed_conversions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONVERSION STATISTICS\n",
      "================================================================================\n",
      "Total data processed: 182.22 GB → 75.52 GB\n",
      "Average compression: 2.42x\n",
      "Average throughput: 27.8 MB/s\n",
      "Total conversion time: 46.6 min\n",
      "\n",
      "Statistics saved: conversion_stats_20251030_152208.csv\n"
     ]
    }
   ],
   "source": [
    "if conversion_stats:\n",
    "    df_stats = pd.DataFrame(conversion_stats)\n",
    "\n",
    "    print(\"\\nCONVERSION STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Overall statistics\n",
    "    total_input_mb = df_stats['input_size_mb'].sum()\n",
    "    total_output_mb = df_stats['output_size_mb'].sum()\n",
    "    avg_compression = df_stats['compression_ratio'].mean()\n",
    "    avg_throughput = df_stats['throughput_mb_per_sec'].mean()\n",
    "    total_conversion_time = df_stats['time_sec'].sum()\n",
    "\n",
    "    print(f\"Total data processed: {total_input_mb/1024:.2f} GB → {total_output_mb/1024:.2f} GB\")\n",
    "    print(f\"Average compression: {avg_compression:.2f}x\")\n",
    "    print(f\"Average throughput: {avg_throughput:.1f} MB/s\")\n",
    "    print(f\"Total conversion time: {total_conversion_time/60:.1f} min\")\n",
    "\n",
    "    # Save statistics\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    stats_file = OUTPUT_ROOT / f\"conversion_stats_{timestamp}.csv\"\n",
    "    df_stats.to_csv(stats_file, index=False)\n",
    "    print(f\"\\nStatistics saved: {stats_file.name}\")\n",
    "\n",
    "    # Save failed conversions if any\n",
    "    if failed_conversions:\n",
    "        df_failed = pd.DataFrame(failed_conversions)\n",
    "        failed_file = OUTPUT_ROOT / f\"failed_conversions_{timestamp}.csv\"\n",
    "        df_failed.to_csv(failed_file, index=False)\n",
    "        print(f\"Failed conversions logged: {failed_file.name}\")\n",
    "else:\n",
    "    print(\"No conversions completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Verify a few random converted files can be read back correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conversion_stats and len(conversion_stats) > 0:\n",
    "    # Verify a few random samples\n",
    "    num_to_test = min(3, len(conversion_stats))\n",
    "    test_samples = df_stats.sample(n=num_to_test)\n",
    "\n",
    "    print(\"\\nVERIFYING RANDOM SAMPLES\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for idx, row in test_samples.iterrows():\n",
    "        timepoint = row['timepoint']\n",
    "        camera_file = row['camera_file']\n",
    "\n",
    "        # Reconstruct zarr path\n",
    "        zarr_name = Path(camera_file).stem + \".zarr\"\n",
    "        zarr_path = OUTPUT_ROOT / timepoint / zarr_name\n",
    "\n",
    "        try:\n",
    "            # Try mbo.imread first\n",
    "            verified = mbo.imread(zarr_path)\n",
    "            print(f\"{zarr_path.parent.name}/{zarr_path.name}: OK ({verified.shape})\")\n",
    "        except Exception as e:\n",
    "            # Fallback to zarr\n",
    "            try:\n",
    "                import zarr\n",
    "                z = zarr.open(zarr_path, mode='r')\n",
    "                print(f\"{zarr_path.parent.name}/{zarr_path.name}: OK ({z.shape})\")\n",
    "            except Exception as e2:\n",
    "                print(f\"{zarr_path.parent.name}/{zarr_path.name}: ERROR - {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Final summary and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Processed 804 volumes in 47.1 minutes\n",
      "Data: 182.2 GB → 75.5 GB\n",
      "Space saved: 106.7 GB (58.6%)\n",
      "Average speed: 27.8 MB/s\n",
      "\n",
      "Output: \\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\zarr\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if conversion_stats:\n",
    "    total_input_gb = df_stats['input_size_mb'].sum() / 1024\n",
    "    total_output_gb = df_stats['output_size_mb'].sum() / 1024\n",
    "    space_saved_gb = total_input_gb - total_output_gb\n",
    "    space_saved_pct = (space_saved_gb / total_input_gb * 100) if total_input_gb > 0 else 0\n",
    "\n",
    "    print(f\"Processed {len(conversion_stats)} volumes in {total_elapsed/60:.1f} minutes\")\n",
    "    print(f\"Data: {total_input_gb:.1f} GB → {total_output_gb:.1f} GB\")\n",
    "    print(f\"Space saved: {space_saved_gb:.1f} GB ({space_saved_pct:.1f}%)\")\n",
    "    print(f\"Average speed: {avg_throughput:.1f} MB/s\")\n",
    "\n",
    "    if failed_conversions:\n",
    "        print(f\"\\nWARNING: {len(failed_conversions)} conversions failed (see logs)\")\n",
    "\n",
    "    print(f\"\\nOutput: {OUTPUT_ROOT}\")\n",
    "else:\n",
    "    print(\"No files were converted\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidation function defined\n"
     ]
    }
   ],
   "source": [
    "def consolidate_camera_volume(camera_id: str, zarr_paths: List[Path],\n",
    "                              output_path: Path, axis_order: str = \"TZYX\",\n",
    "                              compression_level: int = 1) -> Dict:\n",
    "    \"\"\"\n",
    "    Consolidate multiple single-timepoint zarr files into one multi-timepoint volume.\n",
    "\n",
    "    Args:\n",
    "        camera_id: Camera identifier (e.g., 'SPM00_CM00_CHN01')\n",
    "        zarr_paths: List of zarr file paths sorted by timepoint\n",
    "        output_path: Output path for consolidated zarr\n",
    "        axis_order: Either \"TZYX\" (time, z, y, x) or \"ZTYX\" (z, time, y, x)\n",
    "        compression_level: GZip compression level (1-9)\n",
    "\n",
    "    Returns:\n",
    "        Dict with statistics\n",
    "    \"\"\"\n",
    "    import dask.array as da\n",
    "\n",
    "    print(f\"  Loading {len(zarr_paths)} timepoints...\")\n",
    "\n",
    "    # Load all timepoints as dask arrays\n",
    "    volumes = []\n",
    "    for zpath in zarr_paths:\n",
    "        try:\n",
    "            z = zarr.open(zpath, mode='r')\n",
    "            # Get the data array (usually at '0' key for zarr v3)\n",
    "            if hasattr(z, 'keys'):\n",
    "                # It's a group, get the first array\n",
    "                arr_key = list(z.keys())[0]\n",
    "                arr = da.from_zarr(z[arr_key])\n",
    "            else:\n",
    "                # It's already an array\n",
    "                arr = da.from_zarr(z)\n",
    "\n",
    "            # Remove singleton channel dimension if present\n",
    "            # Shape might be (Z, C, Y, X) or (Z, Y, X)\n",
    "            if arr.ndim == 4 and arr.shape[1] == 1:\n",
    "                arr = arr[:, 0, :, :]  # Now (Z, Y, X)\n",
    "\n",
    "            volumes.append(arr)\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR loading {zpath.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    if not volumes:\n",
    "        print(f\"    ERROR: No volumes loaded\")\n",
    "        return None\n",
    "\n",
    "    # Stack along time dimension\n",
    "    # volumes is list of (Z, Y, X) arrays\n",
    "    stacked = da.stack(volumes, axis=0)  # Shape: (T, Z, Y, X)\n",
    "\n",
    "    # Reorder axes if needed\n",
    "    if axis_order == \"ZTYX\":\n",
    "        # Transpose from (T, Z, Y, X) to (Z, T, Y, X)\n",
    "        stacked = da.transpose(stacked, (1, 0, 2, 3))\n",
    "    elif axis_order != \"TZYX\":\n",
    "        raise ValueError(f\"Invalid axis_order: {axis_order}. Must be 'TZYX' or 'ZTYX'\")\n",
    "\n",
    "    print(f\"  Consolidated shape: {stacked.shape} ({axis_order})\")\n",
    "    print(f\"  Writing to {output_path.name}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Remove existing if overwriting\n",
    "    if output_path.exists() and CONSOLIDATE_OVERWRITE:\n",
    "        import shutil\n",
    "        shutil.rmtree(output_path)\n",
    "\n",
    "    # Compute chunk shape - one z-plane per chunk\n",
    "    if axis_order == \"TZYX\":\n",
    "        chunk_shape = (1, 1, stacked.shape[2], stacked.shape[3])\n",
    "    else:  # ZTYX\n",
    "        chunk_shape = (1, 1, stacked.shape[2], stacked.shape[3])\n",
    "\n",
    "    # Write using dask to zarr directly (works with both v2 and v3)\n",
    "    stacked.to_zarr(\n",
    "        str(output_path),\n",
    "        chunks=chunk_shape,\n",
    "        overwrite=CONSOLIDATE_OVERWRITE,\n",
    "        compute=True\n",
    "    )\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Calculate size\n",
    "    output_size_mb = sum(f.stat().st_size for f in output_path.rglob('*') if f.is_file()) / (1024**2)\n",
    "    throughput = output_size_mb / elapsed if elapsed > 0 else 0\n",
    "\n",
    "    print(f\"  Complete: {elapsed:.1f}s @ {throughput:.1f} MB/s, {output_size_mb:.1f} MB\")\n",
    "\n",
    "    return {\n",
    "        'camera_id': camera_id,\n",
    "        'num_timepoints': len(zarr_paths),\n",
    "        'shape': tuple(stacked.shape),\n",
    "        'axis_order': axis_order,\n",
    "        'output_size_mb': output_size_mb,\n",
    "        'time_sec': elapsed,\n",
    "        'throughput_mb_per_sec': throughput\n",
    "    }\n",
    "\n",
    "print(\"Consolidation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating 4 cameras into TZYX volumes...\n",
      "================================================================================\n",
      "[1/4] SPM00_CM00_CHN01:\n",
      "  Loading 201 timepoints...\n",
      "  Consolidated shape: (201, 79, 752, 2048) (TZYX)\n",
      "  Writing to SPM00_CM00_CHN01.zarr...\n",
      "  ERROR: zarr.api.synchronous.create() got multiple values for keyword argument 'chunks'\n",
      "[2/4] SPM00_CM01_CHN01:\n",
      "  Loading 201 timepoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RBO\\AppData\\Local\\Temp\\ipykernel_31376\\3587504223.py\", line 14, in <module>\n",
      "    stats = consolidate_camera_volume(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\RBO\\AppData\\Local\\Temp\\ipykernel_31376\\2515324663.py\", line 77, in consolidate_camera_volume\n",
      "    stacked.to_zarr(\n",
      "  File \"c:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\dask\\array\\core.py\", line 3021, in to_zarr\n",
      "    return to_zarr(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\dask\\array\\core.py\", line 3933, in to_zarr\n",
      "    z = zarr.create(\n",
      "        ^^^^^^^^^^^^\n",
      "TypeError: zarr.api.synchronous.create() got multiple values for keyword argument 'chunks'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Consolidated shape: (201, 79, 752, 2048) (TZYX)\n",
      "  Writing to SPM00_CM01_CHN01.zarr...\n",
      "  ERROR: zarr.api.synchronous.create() got multiple values for keyword argument 'chunks'\n",
      "[3/4] SPM00_CM02_CHN00:\n",
      "  Loading 201 timepoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RBO\\AppData\\Local\\Temp\\ipykernel_31376\\3587504223.py\", line 14, in <module>\n",
      "    stats = consolidate_camera_volume(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\RBO\\AppData\\Local\\Temp\\ipykernel_31376\\2515324663.py\", line 77, in consolidate_camera_volume\n",
      "    stacked.to_zarr(\n",
      "  File \"c:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\dask\\array\\core.py\", line 3021, in to_zarr\n",
      "    return to_zarr(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\dask\\array\\core.py\", line 3933, in to_zarr\n",
      "    z = zarr.create(\n",
      "        ^^^^^^^^^^^^\n",
      "TypeError: zarr.api.synchronous.create() got multiple values for keyword argument 'chunks'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m output_path = CONSOLIDATED_OUTPUT / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.zarr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     stats = \u001b[43mconsolidate_camera_volume\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzarr_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzarr_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAXIS_ORDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCOMPRESSION_LEVEL\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stats:\n\u001b[32m     23\u001b[39m         consolidation_stats.append(stats)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mconsolidate_camera_volume\u001b[39m\u001b[34m(camera_id, zarr_paths, output_path, axis_order, compression_level)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(z, \u001b[33m'\u001b[39m\u001b[33mkeys\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# It's a group, get the first array\u001b[39;00m\n\u001b[32m     29\u001b[39m     arr_key = \u001b[38;5;28mlist\u001b[39m(z.keys())[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     arr = da.from_zarr(\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43marr_key\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# It's already an array\u001b[39;00m\n\u001b[32m     33\u001b[39m     arr = da.from_zarr(z)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\zarr\\core\\group.py:1903\u001b[39m, in \u001b[36mGroup.__getitem__\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> Array | Group:\n\u001b[32m   1877\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Obtain a group member.\u001b[39;00m\n\u001b[32m   1878\u001b[39m \n\u001b[32m   1879\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1901\u001b[39m \n\u001b[32m   1902\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1903\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_async_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1904\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, AsyncArray):\n\u001b[32m   1905\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Array(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\zarr\\core\\sync.py:208\u001b[39m, in \u001b[36mSyncMixin._sync\u001b[39m\u001b[34m(self, coroutine)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sync\u001b[39m(\u001b[38;5;28mself\u001b[39m, coroutine: Coroutine[Any, Any, T]) -> T:\n\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# TODO: refactor this to to take *args and **kwargs and pass those to the method\u001b[39;00m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# this should allow us to better type the sync wrapper\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoroutine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43masync.timeout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RBO\\repos\\millerbrainobservatory.github.io\\.venv\\Lib\\site-packages\\zarr\\core\\sync.py:156\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(coro, loop, timeout)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    154\u001b[39m future = asyncio.run_coroutine_threadsafe(_runner(coro), loop)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m finished, unfinished = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[43m=\u001b[49m\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_COMPLETED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unfinished) > \u001b[32m0\u001b[39m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCoroutine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoro\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed to finish within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:305\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[32m    303\u001b[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m f._condition:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Consolidate all cameras\n",
    "consolidation_stats = []\n",
    "consolidation_start = time.time()\n",
    "\n",
    "print(f\"Consolidating {len(camera_volumes)} cameras into {AXIS_ORDER} volumes...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, (camera_id, zarr_paths) in enumerate(camera_volumes.items(), 1):\n",
    "    print(f\"[{idx}/{len(camera_volumes)}] {camera_id}:\")\n",
    "\n",
    "    output_path = CONSOLIDATED_OUTPUT / f\"{camera_id}.zarr\"\n",
    "\n",
    "    try:\n",
    "        stats = consolidate_camera_volume(\n",
    "            camera_id=camera_id,\n",
    "            zarr_paths=zarr_paths,\n",
    "            output_path=output_path,\n",
    "            axis_order=AXIS_ORDER,\n",
    "            compression_level=COMPRESSION_LEVEL\n",
    "        )\n",
    "\n",
    "        if stats:\n",
    "            consolidation_stats.append(stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "consolidation_elapsed = time.time() - consolidation_start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Consolidation complete in {consolidation_elapsed/60:.1f} minutes\")\n",
    "print(f\"  Successful: {len(consolidation_stats)}/{len(camera_volumes)} cameras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No consolidations completed\n"
     ]
    }
   ],
   "source": [
    "# Consolidation statistics\n",
    "if consolidation_stats:\n",
    "    df_consol = pd.DataFrame(consolidation_stats)\n",
    "\n",
    "    print(\"\\nCONSOLIDATION STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    total_size_mb = df_consol['output_size_mb'].sum()\n",
    "    total_time = df_consol['time_sec'].sum()\n",
    "    avg_throughput = df_consol['throughput_mb_per_sec'].mean()\n",
    "\n",
    "    print(f\"Total consolidated size: {total_size_mb/1024:.2f} GB\")\n",
    "    print(f\"Average throughput: {avg_throughput:.1f} MB/s\")\n",
    "    print(f\"Total processing time: {total_time/60:.1f} min\")\n",
    "\n",
    "    print(\"\\nPer-camera summary:\")\n",
    "    for _, row in df_consol.iterrows():\n",
    "        print(f\"  {row['camera_id']}: {row['shape']} ({row['axis_order']}), {row['output_size_mb']:.1f} MB\")\n",
    "\n",
    "    # Save statistics\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    stats_file = CONSOLIDATED_OUTPUT / f\"consolidation_stats_{timestamp}.csv\"\n",
    "    df_consol.to_csv(stats_file, index=False)\n",
    "    print(f\"\\nStatistics saved: {stats_file.name}\")\n",
    "\n",
    "    print(f\"\\nConsolidated volumes: {CONSOLIDATED_OUTPUT}\")\n",
    "else:\n",
    "    print(\"No consolidations completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidation function defined\n"
     ]
    }
   ],
   "source": [
    "def consolidate_camera_volume(camera_id: str, zarr_paths: List[Path],\n",
    "                              output_path: Path, axis_order: str = \"TZYX\",\n",
    "                              compression_level: int = 1) -> Dict:\n",
    "    \"\"\"\n",
    "    Consolidate multiple single-timepoint zarr files into one multi-timepoint volume.\n",
    "\n",
    "    Args:\n",
    "        camera_id: Camera identifier (e.g., 'SPM00_CM00_CHN01')\n",
    "        zarr_paths: List of zarr file paths sorted by timepoint\n",
    "        output_path: Output path for consolidated zarr\n",
    "        axis_order: Either \"TZYX\" (time, z, y, x) or \"ZTYX\" (z, time, y, x)\n",
    "        compression_level: GZip compression level (1-9)\n",
    "\n",
    "    Returns:\n",
    "        Dict with statistics\n",
    "    \"\"\"\n",
    "    from zarr.codecs import BytesCodec, GzipCodec, ShardingCodec\n",
    "    import dask.array as da\n",
    "\n",
    "    print(f\"  Loading {len(zarr_paths)} timepoints...\")\n",
    "\n",
    "    # Load all timepoints as dask arrays\n",
    "    volumes = []\n",
    "    for zpath in zarr_paths:\n",
    "        try:\n",
    "            z = zarr.open(zpath, mode='r')\n",
    "            # Convert to dask array, shape is (Z, C, Y, X) or (Z, Y, X)\n",
    "            arr = da.from_zarr(z)\n",
    "\n",
    "            # Remove singleton channel dimension if present\n",
    "            if arr.ndim == 4 and arr.shape[1] == 1:\n",
    "                arr = arr[:, 0, :, :]  # Now (Z, Y, X)\n",
    "\n",
    "            volumes.append(arr)\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR loading {zpath.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    if not volumes:\n",
    "        print(f\"    ERROR: No volumes loaded\")\n",
    "        return None\n",
    "\n",
    "    # Stack along time dimension\n",
    "    # volumes is list of (Z, Y, X) arrays\n",
    "    stacked = da.stack(volumes, axis=0)  # Shape: (T, Z, Y, X)\n",
    "\n",
    "    # Reorder axes if needed\n",
    "    if axis_order == \"ZTYX\":\n",
    "        # Transpose from (T, Z, Y, X) to (Z, T, Y, X)\n",
    "        stacked = da.transpose(stacked, (1, 0, 2, 3))\n",
    "    elif axis_order != \"TZYX\":\n",
    "        raise ValueError(f\"Invalid axis_order: {axis_order}. Must be 'TZYX' or 'ZTYX'\")\n",
    "\n",
    "    print(f\"  Consolidated shape: {stacked.shape} ({axis_order})\")\n",
    "    print(f\"  Writing to {output_path.name}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Write consolidated zarr\n",
    "    # Use sharding for better performance\n",
    "    chunk_shape = (1, 1, stacked.shape[2], stacked.shape[3])  # Single plane chunks\n",
    "\n",
    "    if USE_SHARDING:\n",
    "        shard_shape = (1, stacked.shape[1], stacked.shape[2], stacked.shape[3])  # One full volume\n",
    "        codecs = [\n",
    "            ShardingCodec(\n",
    "                chunk_shape=chunk_shape,\n",
    "                codecs=[\n",
    "                    BytesCodec(),\n",
    "                    GzipCodec(level=compression_level)\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        codecs = [\n",
    "            BytesCodec(),\n",
    "            GzipCodec(level=compression_level)\n",
    "        ]\n",
    "\n",
    "    # Remove existing if overwriting\n",
    "    if output_path.exists() and CONSOLIDATE_OVERWRITE:\n",
    "        import shutil\n",
    "        shutil.rmtree(output_path)\n",
    "\n",
    "    # Create zarr store\n",
    "    store = zarr.DirectoryStore(output_path)\n",
    "\n",
    "    # Write with zarr v3\n",
    "    root = zarr.group(store=store, overwrite=CONSOLIDATE_OVERWRITE)\n",
    "\n",
    "    # Create array\n",
    "    z_arr = root.create_array(\n",
    "        '0',\n",
    "        shape=stacked.shape,\n",
    "        chunks=chunk_shape,\n",
    "        dtype=stacked.dtype,\n",
    "        codecs=codecs,\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    # Write data\n",
    "    da.to_zarr(stacked, z_arr, compute=True)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Calculate size\n",
    "    output_size_mb = sum(f.stat().st_size for f in output_path.rglob('*') if f.is_file()) / (1024**2)\n",
    "    throughput = output_size_mb / elapsed if elapsed > 0 else 0\n",
    "\n",
    "    print(f\"  Complete: {elapsed:.1f}s @ {throughput:.1f} MB/s, {output_size_mb:.1f} MB\")\n",
    "\n",
    "    return {\n",
    "        'camera_id': camera_id,\n",
    "        'num_timepoints': len(zarr_paths),\n",
    "        'shape': stacked.shape,\n",
    "        'axis_order': axis_order,\n",
    "        'output_size_mb': output_size_mb,\n",
    "        'time_sec': elapsed,\n",
    "        'throughput_mb_per_sec': throughput\n",
    "    }\n",
    "\n",
    "print(\"Consolidation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 4 unique cameras:\n",
      "  SPM00_CM00_CHN01: 201 timepoints\n",
      "  SPM00_CM01_CHN01: 201 timepoints\n",
      "  SPM00_CM02_CHN00: 201 timepoints\n",
      "  SPM00_CM03_CHN00: 201 timepoints\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "from collections import defaultdict\n",
    "\n",
    "def discover_camera_volumes(zarr_root: Path) -> Dict[str, List[Path]]:\n",
    "    \"\"\"\n",
    "    Discover all zarr files and group them by camera.\n",
    "\n",
    "    Returns dict mapping camera name to list of zarr paths sorted by timepoint.\n",
    "    Example: {'SPM00_CM00_CHN01': [path1, path2, ...]}\n",
    "    \"\"\"\n",
    "    camera_groups = defaultdict(list)\n",
    "\n",
    "    # Scan all timepoint directories\n",
    "    for tp_dir in sorted(zarr_root.glob(\"TM*\")):\n",
    "        if not tp_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        # Find all zarr files in this timepoint\n",
    "        for zarr_path in tp_dir.glob(\"*.zarr\"):\n",
    "            # Extract camera identifier from filename\n",
    "            # SPM00_TM000000_CM00_CHN01.zarr -> SPM00_CM00_CHN01\n",
    "            parts = zarr_path.stem.split('_')\n",
    "\n",
    "            # Find CM and CHN parts\n",
    "            camera_parts = ['SPM00']\n",
    "            for part in parts:\n",
    "                if part.startswith('CM') or part.startswith('CHN'):\n",
    "                    camera_parts.append(part)\n",
    "\n",
    "            camera_id = '_'.join(camera_parts)\n",
    "            camera_groups[camera_id].append(zarr_path)\n",
    "\n",
    "    # Sort each camera's timepoints\n",
    "    for camera_id in camera_groups:\n",
    "        camera_groups[camera_id] = sorted(camera_groups[camera_id])\n",
    "\n",
    "    return dict(camera_groups)\n",
    "\n",
    "\n",
    "# Discover all camera volumes\n",
    "camera_volumes = discover_camera_volumes(OUTPUT_ROOT)\n",
    "\n",
    "print(f\"Discovered {len(camera_volumes)} unique cameras:\")\n",
    "for camera_id, paths in camera_volumes.items():\n",
    "    print(f\"  {camera_id}: {len(paths)} timepoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidation configuration:\n",
      "  Input: \\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\zarr\n",
      "  Output: \\\\rbo-s1\\S1_DATA\\isoview\\foconnell\\io_corrected_test\\zarr_consolidated\n",
      "  Axis order: TZYX\n",
      "  Overwrite: True\n"
     ]
    }
   ],
   "source": [
    "# Configuration for consolidation\n",
    "CONSOLIDATED_OUTPUT = OUTPUT_ROOT.parent / \"zarr_consolidated\"\n",
    "AXIS_ORDER = \"TZYX\"  # Options: \"TZYX\" (time first) or \"ZTYX\" (z first)\n",
    "CONSOLIDATE_OVERWRITE = True\n",
    "\n",
    "# Create output directory\n",
    "CONSOLIDATED_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Consolidation configuration:\")\n",
    "print(f\"  Input: {OUTPUT_ROOT}\")\n",
    "print(f\"  Output: {CONSOLIDATED_OUTPUT}\")\n",
    "print(f\"  Axis order: {AXIS_ORDER}\")\n",
    "print(f\"  Overwrite: {CONSOLIDATE_OVERWRITE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "millerbrainobservatory-github-io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
